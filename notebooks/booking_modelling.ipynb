{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Preprocessamento\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from feature_engine.selection import DropConstantFeatures, DropCorrelatedFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, PowerTransformer, PolynomialFeatures\n",
    "\n",
    "# Modelos\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração dos dados\n",
    "\n",
    "Nesta sessão, irei explorar os dados para entender melhor o que está por trás e\n",
    "decidir como a parte de experimentação será realizada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impressões iniciais\n",
    "\n",
    "Nesta etapa irei observar os dados de forma superficial para entender como estão\n",
    "estruturados e quais informações estão disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando os dados\n",
    "dados = pd.read_csv('../data/raw/customer_booking.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando como os dados estão\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o tamanho do dataset\n",
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a info sobre os dados\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se há valores duplicados\n",
    "dados.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações a partir da análise inicial\n",
    "\n",
    "A partir das informações iniciais, podemos entender que temos um dataset com 50 \n",
    "mil registros e 14 colunas, onde tais registros não estão atribuídos a um \n",
    "usuário em específico. Devido a essa condição, podemos observar dados duplicados.\n",
    "\n",
    "Além disso, podemos perceber que o tipo de dado da maior parte das colunas está \n",
    "coerente com o seu conteúdo, com exceção das colunas **wants_extra_baggage**, \n",
    "**wants_preferred_seat** e **wants_in_flight_meals**, que são colunas \n",
    "categóricas que foram previamente codificadas. \n",
    "\n",
    "Por último, também é possível perceber que não existem valores ausentes.\n",
    "\n",
    "O nosso target está na coluna **booking complete**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando correções iniciais\n",
    "\n",
    "Nesta etapa, irei apenas excluir os dados duplicados. Também será realizada a \n",
    "correção no tipo dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando dados duplicados\n",
    "dados = dados.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o tipo de dado da coluna 'wants_extra_baggage'\n",
    "dados['wants_extra_baggage'] = dados['wants_extra_baggage'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o tipo de dado da coluna 'wants_preferred_seat'\n",
    "dados['wants_preferred_seat'] = dados['wants_preferred_seat'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o tipo de dado da coluna 'wants_in_flight_meals'\n",
    "dados['wants_in_flight_meals'] = dados['wants_in_flight_meals'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando as variáveis categóricas\n",
    "Nesta etapa, irei verificar se existem valores raros em cada coluna. Caso \n",
    "existam, será necessário uni-los em uma única categoria, pois valores raros\n",
    "podem compremeter o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as colunas categóricas\n",
    "cat_cols = dados.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas categóricas\n",
    "dados.loc[:, cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'sales_channel'\n",
    "dados['sales_channel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'trip_type'\n",
    "dados['trip_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'flight_day'\n",
    "dados['flight_day'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'route'\n",
    "dados['route'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'booking_origin'\n",
    "dados['booking_origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'wants_extra_baggage'\n",
    "dados['wants_extra_baggage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'wants_preferred_seat'\n",
    "dados['wants_preferred_seat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem registros raros na coluna 'wants_in_flight_meals'\n",
    "dados['wants_in_flight_meals'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações a partir da análise das variáveis categóricas\n",
    "A partir das 6 colunas categóricas, podemos observar que existem valores raros\n",
    "em duas delas: **route** e **booking_origin**. Portanto, irei agrupar os valores\n",
    "raros em uma nova categoria. Tais categorias serão agrupadas em uma única de nome\n",
    "**'others'**. Além disso, ainda é possível observar que essas features possuem \n",
    "uma alta cardinalidade, o que pode ser um problema para o treinamento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrigindo as variáveis categóricas que apresentaram problemas\n",
    "Nesta fase, os dados com menos de 4 registros serão agrupados em uma nova \n",
    "categoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booking origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando os registros que atendem ao critério de raridade\n",
    "country_booking_less_than_four = dados['booking_origin'].value_counts() < 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando em uma lista os paises que atendem ao critério de raridade\n",
    "countries = dados['booking_origin'].value_counts()[country_booking_less_than_four].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para substituir os registros raros por 'other'\n",
    "func_rare_registry = lambda country: 'other' if country in countries else country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função\n",
    "dados['booking_origin'] = dados['booking_origin'].apply(func_rare_registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando os registros que atendem ao critério de raridade\n",
    "route_less_than_four = dados['route'].value_counts() < 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando em uma lista os paises que atendem ao critério de raridade\n",
    "routes = dados['route'].value_counts()[route_less_than_four].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para substituir os registros raros por 'other'\n",
    "func_rare_registry = lambda route: 'other' if route in routes else route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função\n",
    "dados['route'] = dados['route'].apply(func_rare_registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando as variáveis numéricas\n",
    "Na segunda parte, irei observar as variáveis numéricas para entender a \n",
    "variabilidade dos dados e se existem outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as colunas numéricas\n",
    "num_cols = dados.select_dtypes(['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os dados numéricos\n",
    "dados.loc[:, num_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos dados da coluna 'num_passengers'\n",
    "dados['num_passengers'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos dados da coluna 'purchase_lead'\n",
    "dados['purchase_lead'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos dados da coluna 'length_of_stay'\n",
    "dados['length_of_stay'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos dados da coluna 'flight_hour'\n",
    "dados['flight_hour'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos dados da coluna 'flight_duration'\n",
    "dados['flight_duration'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações a partir da análise das variáveis numéricas\n",
    "A partir das colunas examinadas, podemos observar que existem outliers em três\n",
    "delas. Entretanto, tais outliers aparentam ser naturais, e não provenientes de\n",
    "erros de digitação ou de coleta de dados. Portanto, não serão tratados.\n",
    "\n",
    "Além disso, os dados apresentam uma variabilidade considerável, fazendo com\n",
    "não seja necessário realizar nenhum tipo de exclusão de coluna.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando o target\n",
    "E por último, o target será analisado para verificar se há desbalanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['booking_complete'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações a partir da análise do target\n",
    "\n",
    "A partir da análise do target, podemos observar que o dataset está desbalanceado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando novas features\n",
    "\n",
    "Nesta fase, irei criar novas features a partir das variáveis existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para determinar em que parte do dia o voo ocorre\n",
    "func_time_of_day = lambda hour: 'morning' if hour >= 6 and hour < 12 else ('afternoon' if hour >= 12 and hour < 18 else 'night')\n",
    "\n",
    "# Aplicando a função\n",
    "dados['time_of_day'] = dados['flight_hour'].apply(func_time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a hora de chegada\n",
    "dados['arrival_hour'] = dados['flight_hour'] + dados['flight_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para verificar se o voo chega no mesmo dia\n",
    "func_same_day = lambda hour: 'yes' if hour < 24 else 'no'\n",
    "\n",
    "# Aplicando a função\n",
    "dados['same_day_arrival'] = dados['arrival_hour'].apply(func_same_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para checar se a viagem vai ocorrer no final de semana\n",
    "func_weekend = lambda day: 'yes' if day == 'Sat' or day == 'Sun' else 'no'\n",
    "\n",
    "# Aplicando a função\n",
    "dados['weekend_trip'] = dados['flight_day'].apply(func_weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o tempo de estadia em meses\n",
    "dados['length_of_stay_months'] = dados['length_of_stay'] / 30\n",
    "\n",
    "# calculando o tempo de estadia em semanas\n",
    "dados['length_of_stay_years'] = dados['length_of_stay'] / 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentação\n",
    "Aqui, irei realizar a experimentação para encontrar o melhor modelo para o\n",
    "problema em questão. \n",
    "\n",
    "Inicialmente, irei testar um modelo de classificação que é sensível a\n",
    "escala dos dados: a **Logistic Regression**. Em seguida, irei incluir \n",
    "os modelos baseados em árvore: **Decision Tree**, **Random Forest**, \n",
    "**AdaBoost** e **LightGBM**.\n",
    "\n",
    "Como métrica de avaliação, irei usar a **AUC**. Além disso, irei usar a\n",
    "Cross Validation para avaliar a performance dos modelos, registrando o \n",
    "desempenho de cada fold e a média final.\n",
    "\n",
    "Para acessar os experimentos, digite o comando abaixo no terminal:\n",
    "\n",
    "```mlflow ui```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o local para salvar os exoerimentos\n",
    "mlflow.set_tracking_uri('../mlruns')\n",
    "\n",
    "# Criando/acessando o experimento\n",
    "mlflow.set_experiment('Comparando modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em variáveis dependentes e independentes\n",
    "x = dados.drop(columns='booking_complete')\n",
    "y = dados['booking_complete']\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=0.15,\n",
    "                                                        random_state=200)\n",
    "\n",
    "# Dividindo os dados em dev e teste\n",
    "x_dev, x_teste, y_dev, y_teste = train_test_split(x_teste,\n",
    "                                                  y_teste,\n",
    "                                                  test_size=0.50,\n",
    "                                                  random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as colunas com alta dimensionalidade\n",
    "high_dim_cols = ['route', 'booking_origin']\n",
    "\n",
    "# Obtendo as colunas categóricas\n",
    "cat_cols = x.select_dtypes(include='object').columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col not in high_dim_cols]\n",
    "\n",
    "# Obtendo as colunas numéricas\n",
    "num_cols = x.select_dtypes(['int', 'float']).columns.tolist()\n",
    "\n",
    "# Instanciando um KFold Estratificado\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dicionário com os modelos\n",
    "dict_models_scale_sensitive = {\"LR\": LogisticRegression(random_state=200,\n",
    "                                                        class_weight='balanced')}\n",
    "\n",
    "dict_models_tree_based = {\"LGBM\": LGBMClassifier(is_unbalance=True,\n",
    "                                                 random_state=200),\n",
    "                          \"DT\": DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                       random_state=200),\n",
    "                          \"RF\": RandomForestClassifier(class_weight='balanced',\n",
    "                                                       random_state=200),\n",
    "                          \"ADA\": AdaBoostClassifier(DecisionTreeClassifier(class_weight='balanced',\n",
    "                                                                           random_state=200))}\n",
    "\n",
    "# Criando dicionário com os encoders\n",
    "dict_encoders = {\"OHE\": OneHotEncoder(drop='first'),\n",
    "                 \"TE\": ce.TargetEncoder(),\n",
    "                 \"BE\": ce.BinaryEncoder(),\n",
    "                 \"ME\": ce.MEstimateEncoder(),\n",
    "                 \"WOE\": ce.WOEEncoder(),\n",
    "                 \"CE\": ce.CatBoostEncoder(),\n",
    "                 \"GE\":ce.GrayEncoder()}\n",
    "\n",
    "dict_scalers = {\"SS\": StandardScaler(),\n",
    "                \"RS\": RobustScaler()}\n",
    "\n",
    "# Criando dicionário com os transformers\n",
    "dict_transformers = {\"PT\": PowerTransformer(),\n",
    "                     \"PF\": PolynomialFeatures()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando os experimentos sem transformers\n",
    "for tag, model in dict_models_scale_sensitive.items():\n",
    "    for tag_encoder, encoder in dict_encoders.items():\n",
    "        for tag_scaler, scaler in dict_scalers.items():\n",
    "            \n",
    "            # Gerando a tag de identificação do modelo\n",
    "            nome_modelo = f'{tag}_{tag_encoder}_{tag_scaler}'\n",
    "            \n",
    "            with mlflow.start_run(run_name=nome_modelo):\n",
    "                 \n",
    "                 # Criando os pipeline com os transformers\n",
    "                 pipe_cat = Pipeline([('encoder', encoder)])\n",
    "                 pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "                 pipe_num = Pipeline([('scaler', scaler)])\n",
    "                 \n",
    "                 # Criando o transformador\n",
    "                 transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                                 ('num', pipe_num, num_cols),\n",
    "                                                 ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "                 \n",
    "                 # Criando o pipeline final\n",
    "                 pipe = Pipeline([('transformer', transformer),\n",
    "                                  ('remove_corr', DropCorrelatedFeatures()),\n",
    "                                  ('remove_const', DropConstantFeatures()),\n",
    "                                 ('model', model)])\n",
    "                 \n",
    "                 # Executando o cross validation\n",
    "                 cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='roc_auc')\n",
    "                 \n",
    "                 # Calculando a média das métricas\n",
    "                 mean_score = cross_val_scores.mean()\n",
    "                 \n",
    "                 # Salvando a tag de identificação\n",
    "                 mlflow.set_tag('modelo', tag)               \n",
    "                 \n",
    "                 # Salvando a métrica da folder 1\n",
    "                 mlflow.log_metric('roc_auc_fold_1', cross_val_scores[0])\n",
    "                 \n",
    "                 # Salvando a métrica da folder 2\n",
    "                 mlflow.log_metric('roc_auc_fold_2', cross_val_scores[1])\n",
    "                \n",
    "                 # Salvando a métrica da folder 3\n",
    "                 mlflow.log_metric('roc_auc_fold_3', cross_val_scores[2])\n",
    "                \n",
    "                 # Salvando a métrica da folder 4\n",
    "                 mlflow.log_metric('roc_auc_fold_4', cross_val_scores[3])\n",
    "                \n",
    "                 # Salvando a métrica da folder 5\n",
    "                 mlflow.log_metric('roc_auc_fold_5', cross_val_scores[4])\n",
    "                 \n",
    "                 # Salvando as métricas\n",
    "                 mlflow.log_metric('roc_auc_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando os experimentos com transformers\n",
    "for tag, model in dict_models_scale_sensitive.items():\n",
    "    for tag_encoder, encoder in dict_encoders.items():\n",
    "        for tag_scaler, scaler in dict_scalers.items():\n",
    "            for tag_transformer, transformer in dict_transformers.items():\n",
    "            \n",
    "                # Gerando a tag de identificação do modelo\n",
    "                nome_modelo = f'{tag}_{tag_encoder}_{tag_scaler}_{tag_transformer}'\n",
    "\n",
    "                with mlflow.start_run(run_name=nome_modelo):\n",
    "\n",
    "                     # Criando os pipeline com os transformers\n",
    "                     pipe_cat = Pipeline([('encoder', encoder)])\n",
    "                     pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "                     pipe_num = Pipeline([('scaler', scaler),\n",
    "                                          ('transformer', transformer)])\n",
    "\n",
    "                     # Criando o transformador\n",
    "                     transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                                     ('num', pipe_num, num_cols),\n",
    "                                                     ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "\n",
    "                     # Criando o pipeline final\n",
    "                     pipe = Pipeline([('transformer', transformer),\n",
    "                                     ('remove_corr', DropCorrelatedFeatures()),\n",
    "                                     ('remove_const', DropConstantFeatures()),\n",
    "                                     ('model', model)])\n",
    "\n",
    "                     # Executando o cross validation\n",
    "                     cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='roc_auc')\n",
    "\n",
    "                     # Calculando a média das métricas\n",
    "                     mean_score = cross_val_scores.mean()\n",
    "\n",
    "                     # Salvando a tag de identificação\n",
    "                     mlflow.set_tag('modelo', tag)               \n",
    "\n",
    "                     # Salvando a métrica da folder 1\n",
    "                     mlflow.log_metric('roc_auc_fold_1', cross_val_scores[0])\n",
    "\n",
    "                     # Salvando a métrica da folder 2\n",
    "                     mlflow.log_metric('roc_auc_fold_2', cross_val_scores[1])\n",
    "\n",
    "                     # Salvando a métrica da folder 3\n",
    "                     mlflow.log_metric('roc_auc_fold_3', cross_val_scores[2])\n",
    "\n",
    "                     # Salvando a métrica da folder 4\n",
    "                     mlflow.log_metric('roc_auc_fold_4', cross_val_scores[3])\n",
    "\n",
    "                     # Salvando a métrica da folder 5\n",
    "                     mlflow.log_metric('roc_auc_fold_5', cross_val_scores[4])\n",
    "\n",
    "                     # Salvando as métricas\n",
    "                     mlflow.log_metric('roc_auc_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando os experimentos sem transformers\n",
    "for tag, model in dict_models_tree_based.items():\n",
    "    for tag_encoder, encoder in dict_encoders.items():\n",
    "            \n",
    "            # Gerando a tag de identificação do modelo\n",
    "            nome_modelo = f'{tag}_{tag_encoder}'\n",
    "            \n",
    "            with mlflow.start_run(run_name=nome_modelo):\n",
    "                 \n",
    "                 # Criando os pipeline com os transformers\n",
    "                 pipe_cat = Pipeline([('encoder', encoder)])\n",
    "                 pipe_high_dim = Pipeline([('encoder', ce.CountEncoder())])\n",
    "                 \n",
    "                 # Criando o transformador\n",
    "                 transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                                 ('high_dim', pipe_high_dim, high_dim_cols)])\n",
    "                 \n",
    "                 # Criando o pipeline final\n",
    "                 pipe = Pipeline([('transformer', transformer),\n",
    "                                 ('remove_corr', DropCorrelatedFeatures()),\n",
    "                                 ('remove_const', DropConstantFeatures()),\n",
    "                                 ('model', model)])\n",
    "                 \n",
    "                 # Executando o cross validation\n",
    "                 cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='roc_auc')\n",
    "                 \n",
    "                 # Calculando a média das métricas\n",
    "                 mean_score = cross_val_scores.mean()\n",
    "                 \n",
    "                 # Salvando a tag de identificação\n",
    "                 mlflow.set_tag('modelo', tag)               \n",
    "                 \n",
    "                 # Salvando a métrica da folder 1\n",
    "                 mlflow.log_metric('roc_auc_fold_1', cross_val_scores[0])\n",
    "                 \n",
    "                 # Salvando a métrica da folder 2\n",
    "                 mlflow.log_metric('roc_auc_fold_2', cross_val_scores[1])\n",
    "                \n",
    "                 # Salvando a métrica da folder 3\n",
    "                 mlflow.log_metric('roc_auc_fold_3', cross_val_scores[2])\n",
    "                \n",
    "                 # Salvando a métrica da folder 4\n",
    "                 mlflow.log_metric('roc_auc_fold_4', cross_val_scores[3])\n",
    "                \n",
    "                 # Salvando a métrica da folder 5\n",
    "                 mlflow.log_metric('roc_auc_fold_5', cross_val_scores[4])\n",
    "                 \n",
    "                 # Salvando as métricas\n",
    "                 mlflow.log_metric('roc_auc_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os resultados\n",
    "resultados_experimentos = mlflow.search_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>metrics.roc_auc_fold_1</th>\n",
       "      <th>metrics.roc_auc_fold_2</th>\n",
       "      <th>metrics.roc_auc_fold_3</th>\n",
       "      <th>metrics.roc_auc_fold_4</th>\n",
       "      <th>metrics.roc_auc_fold_5</th>\n",
       "      <th>metrics.roc_auc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LGBM_WOE</td>\n",
       "      <td>0.795743</td>\n",
       "      <td>0.772043</td>\n",
       "      <td>0.769088</td>\n",
       "      <td>0.767051</td>\n",
       "      <td>0.769244</td>\n",
       "      <td>0.774634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LGBM_BE</td>\n",
       "      <td>0.795251</td>\n",
       "      <td>0.771549</td>\n",
       "      <td>0.769222</td>\n",
       "      <td>0.766216</td>\n",
       "      <td>0.768250</td>\n",
       "      <td>0.774097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LGBM_TE</td>\n",
       "      <td>0.795743</td>\n",
       "      <td>0.772043</td>\n",
       "      <td>0.769088</td>\n",
       "      <td>0.764865</td>\n",
       "      <td>0.767550</td>\n",
       "      <td>0.773858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LGBM_ME</td>\n",
       "      <td>0.795743</td>\n",
       "      <td>0.772043</td>\n",
       "      <td>0.769088</td>\n",
       "      <td>0.764865</td>\n",
       "      <td>0.767550</td>\n",
       "      <td>0.773858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LGBM_GE</td>\n",
       "      <td>0.793527</td>\n",
       "      <td>0.771631</td>\n",
       "      <td>0.769129</td>\n",
       "      <td>0.766161</td>\n",
       "      <td>0.768527</td>\n",
       "      <td>0.773795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DT_ME</td>\n",
       "      <td>0.600777</td>\n",
       "      <td>0.589602</td>\n",
       "      <td>0.599350</td>\n",
       "      <td>0.596365</td>\n",
       "      <td>0.601854</td>\n",
       "      <td>0.597590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT_WOE</td>\n",
       "      <td>0.600777</td>\n",
       "      <td>0.589602</td>\n",
       "      <td>0.599350</td>\n",
       "      <td>0.595267</td>\n",
       "      <td>0.598996</td>\n",
       "      <td>0.596799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT_OHE</td>\n",
       "      <td>0.596324</td>\n",
       "      <td>0.587790</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.594546</td>\n",
       "      <td>0.601752</td>\n",
       "      <td>0.595762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DT_CE</td>\n",
       "      <td>0.574956</td>\n",
       "      <td>0.567625</td>\n",
       "      <td>0.569634</td>\n",
       "      <td>0.562030</td>\n",
       "      <td>0.568083</td>\n",
       "      <td>0.568465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADA_CE</td>\n",
       "      <td>0.570795</td>\n",
       "      <td>0.551396</td>\n",
       "      <td>0.568173</td>\n",
       "      <td>0.557740</td>\n",
       "      <td>0.564995</td>\n",
       "      <td>0.562620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tags.mlflow.runName  metrics.roc_auc_fold_1  metrics.roc_auc_fold_2  \\\n",
       "23            LGBM_WOE                0.795743                0.772043   \n",
       "25             LGBM_BE                0.795251                0.771549   \n",
       "26             LGBM_TE                0.795743                0.772043   \n",
       "24             LGBM_ME                0.795743                0.772043   \n",
       "21             LGBM_GE                0.793527                0.771631   \n",
       "..                 ...                     ...                     ...   \n",
       "17               DT_ME                0.600777                0.589602   \n",
       "16              DT_WOE                0.600777                0.589602   \n",
       "20              DT_OHE                0.596324                0.587790   \n",
       "15               DT_CE                0.574956                0.567625   \n",
       "1               ADA_CE                0.570795                0.551396   \n",
       "\n",
       "    metrics.roc_auc_fold_3  metrics.roc_auc_fold_4  metrics.roc_auc_fold_5  \\\n",
       "23                0.769088                0.767051                0.769244   \n",
       "25                0.769222                0.766216                0.768250   \n",
       "26                0.769088                0.764865                0.767550   \n",
       "24                0.769088                0.764865                0.767550   \n",
       "21                0.769129                0.766161                0.768527   \n",
       "..                     ...                     ...                     ...   \n",
       "17                0.599350                0.596365                0.601854   \n",
       "16                0.599350                0.595267                0.598996   \n",
       "20                0.598400                0.594546                0.601752   \n",
       "15                0.569634                0.562030                0.568083   \n",
       "1                 0.568173                0.557740                0.564995   \n",
       "\n",
       "    metrics.roc_auc_mean  \n",
       "23              0.774634  \n",
       "25              0.774097  \n",
       "26              0.773858  \n",
       "24              0.773858  \n",
       "21              0.773795  \n",
       "..                   ...  \n",
       "17              0.597590  \n",
       "16              0.596799  \n",
       "20              0.595762  \n",
       "15              0.568465  \n",
       "1               0.562620  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenando as colunas pela métrica\n",
    "colunas = ['tags.mlflow.runName', 'metrics.roc_auc_fold_1', \n",
    "           'metrics.roc_auc_fold_2', 'metrics.roc_auc_fold_3', \n",
    "           'metrics.roc_auc_fold_4', 'metrics.roc_auc_fold_5', \n",
    "           'metrics.roc_auc_mean']\n",
    "\n",
    "resultados_experimentos.sort_values('metrics.roc_auc_mean', ascending=False).loc[:, colunas]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
